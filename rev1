#Lillian email missing orthologs : EH23a.chr1.v1.g006610.t1 EH23b.chr1.v1.g006360.t1 chr1
#Quant with keep duplicates
#use primary transcripts: s3://salk-tm-shared/csat/releases/scaffolded/EH23a/EH23a.high_confidence.cds.fasta.gz
gunzip EH23a.high_confidence.cds.fasta.gz
gunzip EH23b.high_confidence.cds.fasta.gz
cat EH23a.high_confidence.cds.fasta EH23b.high_confidence.cds.fasta > EH23.concat.primary_high_confidence.cds.fasta
aws s3 cp EH23.concat.primary_high_confidence.cds.fasta s3://salk-tm-dev/cannabis/PanGenome_OCBD/RNA_Seq_Raw_Reads/
conda activate snake 
cd workflows/snake_salmon/
#ERBxHO40 to EH23a/b #SHORT READS
nano workflows/snake_salmon/configs/OCBD_EH23a_b_final.json

nohup snakemake -p -j 12 --use-conda --use-singularity --tibanna \
    --tibanna-config root_ebs_size=32 log_bucket=salk-tm-logs run_name=EH23_salmon_keepdups\
    --default-remote-prefix salk-tm-dev/cannabis/PanGenome_OCBD/RNA_Seq_Raw_Reads/ \
    --default-resources mem_mb=200000 disk_mb=2000000 \
    --configfile configs/EH23_rev1_keepdups.json \
    --config \
        reference=EH23.concat.primary_high_confidence.cds.fasta \
        outbase=quants/EH23_final_salmon_keepdups > logs/EH23_final_salmon12282024.log 2>&1 &





#################################################################
#Eggnog
#/data1/jkitony/Cannabis/rev1_EH23
aws s3 cp s3://salk-tm-shared/csat/releases/scaffolded/EH23a/EH23a.transcript_summary.tsv.gz .
aws s3 cp s3://salk-tm-shared/csat/releases/scaffolded/EH23b/EH23b.transcript_summary.tsv.gz .
gunzip *.gz
(base) jkitony@jkitony:/mnt/c/Cannabis/ms_rev1/IDs_function$ 
cat EH23a.transcript_summary.tsv EH23b.transcript_summary.tsv > EH23ab_transcript_summary.tsv
cat EH23_Early_Flower_category_A.txt EH23_Early_Flower_category_B.txt > EH23_Early_Flower_category_AB.txt

#Annotate ASE genes
awk 'NR==FNR {ids[$1]; next} $1 in ids' EH23_Early_Flower_category_AB.txt EH23ab_transcript_summary.tsv > EH23_Early_Flower_Functions.tsv
awk 'NR==FNR {ids[$1]; next} $2 in ids {print $1, $2, $15, $32}' OFS="\t"  EH23_Early_Flower_category_AB.txt EH23ab_transcript_summary.tsv > EH23_Early_Flower_Functions.tsv

#Lillian GO analysis

#Allele specific expressions
#C:\Cannabis\ms_rev1
import pandas as pd

# Load the orthologs data
df = pd.read_csv('EH23a_EH23b_ortholog_blast_fractionation.txt', sep=' ', header=None, names=["GID1", "GID2", "ID"])
df = df.drop("ID", axis=1)
df.columns = ("GID1", "GID2")
df['GID1'] = df['GID1']
df['GID2'] = df['GID2']

# 1:1 ortholog lifting
C1 = df.GID1.value_counts()
Uniq1 = C1[C1 == 1]
C2 = df.GID2.value_counts()
Uniq2 = C2[C2 == 1]
df0 = df[df.GID1.isin(Uniq1.index) & df.GID2.isin(Uniq2.index)]
out1 = "file22.tsv"
df0.to_csv(out1, sep='\t', index=False)

# Read salmon quant file
quant = pd.read_csv('quant.tsv', sep='\t')
quant = quant.drop(["Length", "EffectiveLength", "NumReads"], axis=1)

# Pivot TPM values
tpms = quant.set_index(['Name', "Sample"]).TPM.unstack().sort_index().sort_index(axis=1)
out = "file11.tsv"
tpms.to_csv(out, sep='\t', index=True)

######################
# Prepare file33.tsv
######################
# Read the TPM values
column_values = {column: {} for column in tpms.columns}

# Populate the dictionary with TPM values
for column in tpms.columns:
    column_values[column] = tpms[column].to_dict()

# Prepare file33.tsv
file33_lines = []

# Add headers for file33.tsv
columns_to_process = ["EH23_Early_Flower", "EH23_Foliage", "EH23_Foliage_12light", "EH23_Late_Flower", "EH23_Roots", "EH23_Shoottips"]
header33 = []
for column in columns_to_process:
    header33.extend([f"{column}_Summary", f"{column}_Value1", f"{column}_Value2"])
file33_lines.append("\t".join(["GID1", "GID2"] + header33) + "\n")

# Read the mapping from file22.tsv and write to file33.tsv
with open("file22.tsv", "r") as file22:
    mapping_lines = file22.readlines()

for line in mapping_lines[1:]:  # Skip the header
    gid1, gid2 = line.strip().split('\t')[:2]
    row = [gid1, gid2]
    for column in columns_to_process:
        value1 = column_values[column].get(gid1, 0)
        value2 = column_values[column].get(gid2, 0)
        
        # Determine the summary category
        if abs(value1 - value2) <= 5:
            summary = "C"
        elif value1 > value2:
            summary = "A"
        else:
            summary = "B"
        
        row.extend([summary, value1, value2])
    file33_lines.append("\t".join(map(str, row)) + "\n")

with open("file33.tsv", "w") as file33:
    file33.writelines(file33_lines)

print("File33.tsv with summaries and TPM values has been created.")

################################################################################################
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import zscore

# Set global style and bold fonts
plt.rcParams.update({
    "font.size": 12,           # Set font size
    "font.weight": "bold",     # Make text bold
    "axes.titleweight": "bold",
    "axes.labelweight": "bold",
    "xtick.labelsize": 10,
    "ytick.labelsize": 10
})
sns.set_context("talk", font_scale=1.2)  # Adjust font scale for publication quality

# Load the data
file33 = pd.read_csv("file33.tsv", sep="\t")

# Extract tissue names
tissues = ["EH23_Early_Flower", "EH23_Foliage", "EH23_Foliage_12light", "EH23_Late_Flower", "EH23_Roots", "EH23_Shoottips"]

# Identify rows biased to Hap1 (at least one "A", no "B")
hap1_mask = (
    file33[[f"{tissue}_Summary" for tissue in tissues]].apply(lambda x: "A" in x.values and "B" not in x.values, axis=1)
)

# Identify rows biased to Hap2 (at least one "B", no "A")
hap2_mask = (
    file33[[f"{tissue}_Summary" for tissue in tissues]].apply(lambda x: "B" in x.values and "A" not in x.values, axis=1)
)

# Filter rows
hap1_data = file33[hap1_mask]
hap2_data = file33[hap2_mask]

# Save gene pairs to files
hap1_data[["GID1", "GID2"]].to_csv("Hap1_biased_genes.tsv", sep="\t", index=False, header=True)
hap2_data[["GID1", "GID2"]].to_csv("Hap2_biased_genes.tsv", sep="\t", index=False, header=True)

# Helper function to prepare heatmap data with z-scoring
def prepare_heatmap_data(data, tissues):
    heatmap_data = []
    row_labels = []

    for index, row in data.iterrows():
        combined_id = f"{row['GID1']}_{row['GID2']}"
        row_labels.append(combined_id)
        values = []
        for tissue in tissues:
            values.extend([row[f"{tissue}_Value1"], row[f"{tissue}_Value2"]])
        
        # Apply z-score normalization to the row values
        values = zscore(values) if len(set(values)) > 1 else values  # Avoid division by zero for constant rows
        heatmap_data.append(values)

    # Convert to DataFrame
    heatmap_df = pd.DataFrame(
        heatmap_data,
        columns=[f"{tissue}_{allele}" for tissue in tissues for allele in ["Allele1", "Allele2"]],
        index=row_labels
    )
    return heatmap_df

# Prepare heatmap data for Hap1 with z-score normalization
hap1_heatmap_data = prepare_heatmap_data(hap1_data, tissues)

# Prepare heatmap data for Hap2 with z-score normalization
hap2_heatmap_data = prepare_heatmap_data(hap2_data, tissues)

# Plot heatmap function with smooth gradient
def plot_heatmap(data, title, output_pdf, output_png):
    plt.figure(figsize=(12, 8))
    sns.heatmap(
        data, cmap="viridis", cbar_kws={"label": "Z-Score"},
        linewidths=0.3, linecolor="gray", center=0
    )
    plt.title(title, fontsize=14, fontweight="bold")
    plt.xlabel("Tissues and Alleles", fontsize=12, fontweight="bold")
    plt.ylabel("1:1 Gene Pairs", fontsize=12, fontweight="bold")
    plt.xticks(fontsize=10, fontweight="bold")
    plt.yticks(fontsize=10, fontweight="bold")
    plt.tight_layout()
    plt.savefig(output_pdf)
    plt.savefig(output_png)
    plt.close()

# Generate Hap1 heatmap
plot_heatmap(hap1_heatmap_data, "Expression Heatmap (Z-Score) - EH23a Bias", 
             "Expression_heatmap_Hap1_ZScore.pdf", "Expression_heatmap_Hap1_ZScore.png")

# Generate Hap2 heatmap
plot_heatmap(hap2_heatmap_data, "Expression Heatmap (Z-Score) - EH23b Bias", 
             "Expression_heatmap_Hap2_ZScore.pdf", "Expression_heatmap_Hap2_ZScore.png")

print("Heatmaps generated as PDF and PNG: Expression_heatmap_Hap1_ZScore and Expression_heatmap_Hap2_ZScore")
print("Gene pairs saved: Hap1_biased_genes.tsv and Hap2_biased_genes.tsv")

##################################
#run and plot topGO and KEGG
##################################
#########################################################################################################################
#########################################################################################################################
#TOPGO ANALYSIS
#########################################################################################################################
#########################################################################################################################

rm(list = ls())
# Set working directory
setwd("C:/Cannabis/ms_rev1")

# Load required packages
library(topGO)
library(dplyr)
library(ggplot2)
library(wordcloud)

# Function to process input files and perform GO enrichment analysis
process_GO_analysis <- function(transcript_file, gene_list_file, output_prefix) {
  # Step 1: Read the EggNOG-mapper TSV file
  eggnog_data <- read.delim(transcript_file, header = TRUE, sep = "\t")
  
  # Step 2: Filter rows with non-empty GO terms
  filtered_data <- eggnog_data %>% filter(GOS != "")
  
  # Step 3: Create a gene2GO mapping
  gene2GO <- filtered_data %>%
    select(TID, GOS) %>%
    mutate(GOS = strsplit(as.character(GOS), ",")) %>% # Split GO terms by commas
    group_by(TID) %>%
    summarise(GOS = list(unique(unlist(GOS)))) %>%
    { setNames(.$GOS, .$TID) } # Convert to a named list
  
  # Step 4: Load Gene List (Genes of Interest)
  genes_of_interest <- read.table(gene_list_file, header = FALSE, stringsAsFactors = FALSE)$V1
  
  # Step 5: Create a named vector for allGenes (1 for genes of interest, 0 otherwise)
  all_genes <- names(gene2GO)
  geneList <- ifelse(all_genes %in% genes_of_interest, 1, 0)
  names(geneList) <- all_genes
  
  # Step 6: Create the topGOdata object
  topGOdata <- new(
    "topGOdata",
    ontology = "BP", # Biological Process
    allGenes = geneList,
    geneSel = function(x) x == 1,
    annot = annFUN.gene2GO,
    gene2GO = gene2GO
  )
  
  # Step 7: Run Enrichment Analysis
  resultFisher <- runTest(topGOdata, algorithm = "classic", statistic = "fisher")
  resultWeight <- runTest(topGOdata, algorithm = "weight01", statistic = "fisher")
  
  # Step 8: Save full results table with all GO terms
  fullResults <- GenTable(
    topGOdata,
    classicFisher = resultFisher,
    weightFisher = resultWeight,
    orderBy = "weightFisher", # Sort by weightFisher
    topNodes = length(score(resultWeight)) # Include all GO terms
  )
  
  # Add adjusted p-values (FDR correction) for weightFisher
  fullResults$p.adj <- p.adjust(as.numeric(fullResults$weightFisher), method = "fdr")
  
  # Save the full results table to a TSV file
  write.table(
    fullResults,
    file = paste0(output_prefix, "_GO_enrichment_full_results_with_padj.tsv"),
    sep = "\t",
    row.names = FALSE,
    quote = FALSE
  )
  
  # Step 9: Generate top 15 results for visualization
  top15Results <- fullResults[1:15, ]
  top15Results$log10_pval <- -log10(as.numeric(top15Results$classicFisher))
  top15Results$GeneRatio <- top15Results$Significant / top15Results$Annotated
  
  # Step 10: Visualization - Bar Plot
  bar_plot <- ggplot(top15Results, aes(x = reorder(Term, log10_pval), y = log10_pval)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    coord_flip() +
    labs(
      title = paste0("Top 15 Enriched GO Terms - ", output_prefix),
      x = "GO Terms",
      y = "-log10(p-value)"
    ) +
    theme_minimal(base_size = 14) +
    theme(
      text = element_text(face = "bold"),
      plot.title = element_text(hjust = 0.5)
    )
  ggsave(paste0(output_prefix, "_GO_enrichment_barplot.pdf"), plot = bar_plot, width = 8, height = 6, dpi = 300)
  ggsave(paste0(output_prefix, "_GO_enrichment_barplot.png"), plot = bar_plot, width = 8, height = 6, dpi = 300)
  
  # Step 11: Visualization - Dot Plot
  dot_plot <- ggplot(top15Results, aes(x = GeneRatio, y = reorder(Term, GeneRatio))) +
    geom_point(aes(size = Significant, color = p.adj)) +
    scale_color_gradient(low = "red", high = "blue", name = "Adjusted p-value") +
    scale_size_continuous(name = "Gene Count") +
    labs(
      title = paste0("Top 15 Enriched GO Terms - ", output_prefix),
      x = "Gene Ratio (Significant/Annotated)",
      y = "GO Terms"
    ) +
    theme_minimal(base_size = 14) +
    theme(
      text = element_text(face = "bold"),
      plot.title = element_text(hjust = 0.5),
      legend.position = "right"
    )
  ggsave(paste0(output_prefix, "_GO_enrichment_dotplot_colored.pdf"), plot = dot_plot, width = 8, height = 6, dpi = 300)
  ggsave(paste0(output_prefix, "_GO_enrichment_dotplot_colored.png"), plot = dot_plot, width = 8, height = 6, dpi = 300)
  
  # Step 12: Visualization - Word Cloud
  words <- top15Results$Term
  freq <- top15Results$log10_pval
  png(paste0(output_prefix, "_GO_enrichment_wordcloud.png"), width = 2000, height = 2000, res = 300)
  wordcloud(words, freq, colors = brewer.pal(8, "Dark2"), random.order = FALSE, scale = c(3, 0.5))
  dev.off()
  pdf(paste0(output_prefix, "_GO_enrichment_wordcloud.pdf"), width = 8, height = 8)
  wordcloud(words, freq, colors = brewer.pal(8, "Dark2"), random.order = FALSE, scale = c(3, 0.5))
  dev.off()
  
  # Return the topGOdata object and results
  list(topGOdata = topGOdata, fullResults = fullResults, top15Results = top15Results)
}

# Process Hap1
hap1_results <- process_GO_analysis(
  transcript_file = "EH23a.transcript_summary.tsv",
  gene_list_file = "Hap1_biased_genes.tsv",
  output_prefix = "Hap1"
)

# Process Hap2
hap2_results <- process_GO_analysis(
  transcript_file = "EH23b.transcript_summary.tsv",
  gene_list_file = "Hap2_biased_genes.tsv",
  output_prefix = "Hap2"
)






